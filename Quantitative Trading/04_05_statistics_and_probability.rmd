---
title: ''
mainfont: Arial
fontsize: 12pt
documentclass: report
header-includes:
- \PassOptionsToPackage{table}{xcolor}
- \usepackage{caption}
- \usepackage{amssymb}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage[table]{xcolor}
- \usepackage{fancyhdr}
- \usepackage{boldline}
- \usepackage{tipa}
   \definecolor{headergrey}{HTML}{545454}
   \definecolor{msdblue}{HTML}{1C93D1}
   \pagestyle{fancy}
   \setlength\headheight{30pt}
   \rhead{\color{headergrey}\today}
   \fancyhead[L]{\color{headergrey}Moretz, Brandon}
   \fancyhead[C]{\Large\bfseries\color{headergrey}Statistics and Probability}
   \rfoot{\color{headergrey}Chapter 4 and 5}
   \lfoot{\color{headergrey}}
   \fancyfoot[C]{\rmfamily\color{headergrey}Quantitative Trading with R}
geometry: left = 1cm, right = 1cm, top = 2cm, bottom = 3cm
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
editor_options: 
  chunk_output_type: console
---


```{r knitr_setup, include = FALSE}

knitr::opts_chunk$set(
   echo = T, 
   eval = TRUE, 
   dev = 'png', 
   fig.width = 9, 
   fig.height = 3.5)

options(knitr.table.format = "latex")

```

```{r report_setup, message = FALSE, warning = FALSE, include = FALSE}

library(data.table, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(scales, quietly = TRUE, warn.conflicts = FALSE)

library(knitr, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)
library(pander, quietly = TRUE, warn.conflicts = FALSE)
library(formattable, quietly = TRUE, warn.conflicts = FALSE)

library(grid, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(extrafont, quietly = TRUE, warn.conflicts = FALSE)
library(tinytex, quietly = TRUE, warn.conflicts = FALSE)

library(xts, quietly = TRUE, warn.conflicts = FALSE)
library(quantmod, quietly = TRUE, warn.conflicts = FALSE)

library(RJSONIO, quietly = TRUE, warn.conflicts = FALSE)
library(XLConnect, quietly = TRUE, warn.conflicts = FALSE)

library(here, quietly = TRUE, warn.conflicts = FALSE)

library(urca, quietly = TRUE, warn.conflicts = FALSE)

options(tinytex.verbose = TRUE)
suppressMessages(library("tidyverse"))

pretty_kable <- function(data, title, dig = 2) {
  kable(data, caption = title, digits = dig) %>%
    kable_styling(bootstrap_options = c("striped", "hover")) %>%
      kableExtra::kable_styling(latex_options = "hold_position")
}

theme_set(theme_light())

# Theme Overrides
theme_update(axis.text.x = element_text(size = 10),
             axis.text.y = element_text(size = 10),
             plot.title = element_text(hjust = 0.5, size = 16, face = "bold", color = "darkgreen"),
             axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
             plot.subtitle = element_text(face = "bold", size = 8, colour = "darkred"),
             legend.title = element_text(size = 12, color = "darkred", face = "bold"),
             legend.position = "right", legend.title.align=0.5,
             panel.border = element_rect(linetype = "solid", 
                                         colour = "lightgray"), 
             plot.margin = unit(c( 0.1, 0.1, 0.1, 0.1), "inches"))

data.dir <- paste0(here::here(), "/Quantitative Trading")

```

```{r pander_setup, include = FALSE}

knitr::opts_chunk$set(comment = NA)

panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

```

#### Chapter 4 and 5

## Statistics and Probability

```{r}
# set seed for reproducability

set.seed(100)

X <- rnorm(1e6, mean = 2.33, sd = 0.5)
mu <- mean(X)
sd <- sd(X)

par(mfrow = c(1, 1))
hist(X, breaks = 100)
abline(v = mu, lwd = 3, lty = 2)
```

```{r}
set.seed(12)

sample5 <- sample(X, 5, replace = T)
sample10 <- sample(X, 10, replace = T)
sample50 <- sample(X, 50, replace = T)
```

```{r}
sample5
```

```{r}
sample10
```

```{r}
sample50
```

```{r}
mean(sample5)
```

```{r}
mean(sample10)
```

```{r}
mean(sample50)
```

```{r}
mean(sample(X, 1000, replace = T))
```

```{r}
mean(sample(X, 1e5, replace = T))
```

```{r}
mean_list <- list()

for(i in 1:10000) {
  mean_list[[i]] <- mean(sample(X, 10, replace = T))
}

hist(unlist(mean_list), breaks = 500,
     xlab = "Mean of 10 samples from X",
     main = "Convergence of sample distribution",
     cex.main = 0.8)
abline(v = mu, lwd = 3, col = "black", lty = 2)
```

```{r}
population <- sample(c(0, 1), 1e6, replace = T)
hist(population, main = "Non-normal", cex.main = 0.8)
abline(v = mean(population), lwd = 3, lty = 3)
```

```{r}
mean_list <- list()
for(i in 1:1e6){
  mean_list[[i]] <- mean(sample(population, 10, replace = T))
}

hist(unlist(mean_list), main = "Distribution of Averagees",
     cex.main = 0.8,
     xlab = "Average of 10 sample")
abline(v = 0.5, lwd = 3)
```

```{r}
population_variance <- function(x) {
  n <- length(x)
  mu <- sum(x) / n
  sum((x - mu)^2)/n
}
```

```{r}
population <- as.numeric(1:1e6)

variance <- population_variance(population)
```

```{r}
output <- list()

for(i in 1:1000){
  output[[i]] <- population_variance(sample(population, 10, replace = T))
}

variance_estimates <- unlist(output)

hist(variance_estimates, breaks = 100, cex.main = 0.9)
average_variance <- mean(variance_estimates)
abline(v = average_variance, lty = 2, lwd = 2)
abline(v = variance, lwd = 2)
```

```{r}
sample_variance <- function(x) {
  n <- length(x)
  mu <- sum(x) / n
  sum((x - mu)^2) / (n - 1)
}

N <- 1e3
output <- vector(mode = "numeric", length = N)

for(i in 1:N)
{
  output[[i]] <- sample_variance(sample(population, 10, replace = T))
}

sample_variance_estimate <- unlist(output)
average_sample_variance <- mean(sample_variance_estimate)
average_sample_variance
```

```{r}
plot(c(-1, 1), c(.5, .5), type = "h", lwd = 3,
     xlim = c(-2, 2), main = "Probability mass function of a coin toss",
     ylab = "Probability",
     xlab = "Random Variable",
     cex.main = 0.9)
```

```{r}
outcomes <- sample(c(0, 1), 1000, replace = T)

set.seed(101)

biased_outcomes <- sample(c(0, 1), 1000, replace = T, prob = c(0.4, 0.6))

```

```{r}
getSymbols("SPY")

spy <- SPY$SPY.Adjusted

# Extract prices and compute statistics
prices <- spy
mean_prices <- round(mean(prices), 2)
sd_prices <- round(sd(prices), 2)

# Plot the histogram along with a legend
hist(prices, breaks = 100, prob = T, cex.main = 0.9)
abline(v = mean_prices, lwd = 2)
legend("topright", cex = 0.8, border = NULL, bty = "n",
       paste("mean = ", mean_prices, "; sd=", sd_prices))
```

```{r, fig.height=5}
plot_4_ranges <- function(data, start_date, end_date, title) {

  # Set the plot window to be 2 rows and 2 columns
  par(mfrow = c(2, 2))
  
  for(i in 1:4) {
    # Create a string with the appropriate date range
    range <- paste(start_date[i], "/", end_date[i], sep = "")

    # Create the price vector and necessary statistics
    time_series <- data[range, ]
    
    mean_data <- round(mean(time_series, na.rm = TRUE), 3)
    sd_data <- round(sd(time_series, na.rm = TRUE), 3)

    # Plot the histogram along with a legend
    hist_title <- paste(title, range)
    hist(time_series, breaks = 100, prob=TRUE,
      xlab = "", main = hist_title, cex.main = 0.8)
    legend("topright", cex = 0.7, bty = 'n',
      paste("mean=", mean_data, "; sd=", sd_data))
  }

  # Reset the plot window
  par(mfrow = c(1, 1))
}

# Define start and end dates of interest
begin_dates <- c("2012-01-01", "2013-06-06",
  "2014-10-10", "2015-03-03")
end_dates <- c("2013-06-05", "2014-09-09",
  "2015-12-30", "2018-01-06")

# Create plots
plot_4_ranges(prices, begin_dates,
  end_dates, "SPY prices for:")
```

```{r, fig.height=5}
# Compute log returns
returns <- diff(log(prices))

# Use the same function as before to plot returns rather than prices
plot_4_ranges(returns, begin_dates, end_dates, "SPY log prices for:")
```

```{r}
test <- ur.kpss(as.numeric(spy))
test

test@teststat

test@cval
```

```{r}
spy_returns <- diff(log(spy))

test.ret <- ur.kpss(as.numeric(spy_returns))
test.ret@teststat

test.ret@cval
```

```{r}
test_post_2013 <- ur.kpss(as.numeric(spy_returns['2013::']))

test_post_2013@teststat
test_post_2013@cval
```

```{r}
# Plot histogram and density
mu <- mean(spy_returns, na.rm = T)
sigma <- sd(spy_returns, na.rm = T)
x <- seq(-5 * sigma, 5 * sigma, length = nrow(spy_returns))

hist(spy_returns, breaks = 100,
     main = "Histogram of returns for SPY",
     cex.main = 0.8, prob = T)
lines(x, dnorm(x, mu, sigma), col = "red", lwd = 2)
```

```{r}
par(mfrow = c(1, 2))

qqnorm(as.numeric(spy_returns),
       main = "SPY empirical returns qqplot()",
       cex.main = 0.8)
qqline(as.numeric(spy_returns), lwd = 2)
grid()

normal_data <- rnorm(nrow(spy_returns), mean = mu, sd = sigma)

qqnorm(normal_data, main = "Normal returns", cex.main = 0.8)
qqline(normal_data, lwd = 2)
grid()
```

```{r}
answer <- shapiro.test(as.numeric(spy_returns))

answer
```

```{r}
set.seed(129)

normal_numbers <- rnorm(5000, 0, 1)
ans <- shapiro.test(normal_numbers)

ans
```

```{r}
normal_numbers[50] <- 1000

shapiro.test(normal_numbers)
```

```{r}
ggplot(data.table(values = normal_numbers), aes(sample = values)) +
  geom_qq() +
  geom_qq_line()
```

```{r}

getSymbols(c("SPY", "VXX"))

date_range <- "2013/1/1::2013/12/31"

spy_prices <- SPY[date_range]$SPY.Close; vxx_prices <- VXX[date_range]$VXX.Close

prices <- merge.xts(spy_prices, vxx_prices, join = "inner")

cor(prices[, c(1, 2)])

returns <- data.table(Date = index(prices), SPY = diff(log(prices$SPY.Close)), diff(log(prices$VXX.Close)))
returns <- returns[-1]

colnames(returns) <- c("Date", "SPY", "VXX")

cor(returns[, c(2, 3)])
```

```{r}
fit1 <- lm(SPY ~ VXX, data = returns)

sqrt(summary(fit1)$r.squared)
```

```{r}
ggplot(returns, aes(VXX, SPY)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "SPX Vs. VXX")
```

```{r}
reg <- lm(SPY.Close ~ VXX.Close - 1, data = prices)
summary(reg)

# cor
sqrt(summary(reg)$r.squared)
```

```{r}
b <- reg$coefficients[1]
a <- reg$coefficients[2]

par(mfrow = c(2, 2))
plot(reg$residuals,
  main = "Residuals through time",
  xlab = "Days", ylab = "Residuals")
hist(reg$residuals, breaks = 100,
  main = "Distribution of residuals",
  xlab = "Residuals")
qqnorm(reg$residuals)
qqline(reg$residuals)
acf(reg$residuals, main = "Autocorrelation")
```

```{r}
vxx_lag_1 <- lag(prices$VXX.Close, k = 1)

head(vxx_lag_1)
```

```{r}
vxx <- merge(prices$VXX.Close, vxx_lag_1)

par(mfrow = c(1, 1))
# Scatter plot of lagged SPY vs. VXX
plot(as.numeric(vxx[, 1]), as.numeric(vxx[, 2]),
  main = "Scatter plot SPY lagged vs. VXX.",
  xlab = "SPY lagged",
  ylab = "VXX",
  cex.main = 0.8,
  cex.axis = 0.8,
  cex.lab = 0.8)
grid()
```

```{r}
par(mfrow = c(1, 1), mar=c(1,1,1,1))

ccf(as.numeric(prices[, 1]), as.numeric(prices[, 2]),
  main = "Cross correlation between SPY and VXX",
  ylab = "Cross correlation", xlab = "Lag", cex.main = 0.8,
  cex.lab = 0.8, cex.axis = 0.8)
```

```{r}
###################################
# The linear in linear regression #
###################################
x <- seq(1:100)
y <- x ^ 2

par(mfrow = c(1, 1))

# Generate the plot
plot(x, y)

# Fit the regression
reg_parabola <- lm(y ~ x)

# Superimpose the best fit line on the plot
abline(reg_parabola, lwd = 2)

# Look at the results
summary(reg_parabola)
## Coefficients:
##               Estimate    Std. Error t value Pr(>|t|)
## (Intercept)  -1717.000   151.683  -11.32   <2e-16 ***
## x              101.000     2.608   38.73   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1

## Residual standard error: 752.7 on 98 degrees of freedom
## Multiple R-squared:  0.9387,Adjusted R-squared:  0.9381
## F-statistic:  1500 on 1 and 98 DF,  p-value: < 2.2e-16
```

```{r}
plot(x, sqrt(y))
reg_transformed <- lm(sqrt(y) ~ x)
abline(reg_transformed)

summary(reg_transformed)
## Coefficients:
##               Estimate Std. Error  t value     Pr(>|t|)
## (Intercept) -5.684e-14  5.598e-15 -1.015e+01   <2e-16 ***
## x            1.000e+00  9.624e-17  1.039e+16   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1

## Residual standard error: 2.778e-14 on 98 degrees of freedom
## Multiple R-squared:      1,Adjusted R-squared:      1
## F-statistic: 1.08e+32 on 1 and 98 DF,  p-value: < 2.2e-16
```

```{r}
##############
# Volatility #
##############

par(mar=c(1,1,1,1))

# Generate 1000 IID numbers from a normal distribution.
z <- rnorm(1000, 0, 1)

sv <- prices[, c(1, 2)]
# Autocorrelation of returns and squared returns

par(mfrow = c(2, 1))

acf(z, main = "returns", cex.main = 0.8,
  cex.lab = 0.8, cex.axis = 0.8)
grid()

acf(z ^ 2, main = "returns squared",
  cex.lab = 0.8, cex.axis = 0.8)
grid()
```

```{r}
par(mfrow = c(1, 1))
acf(sv[, 1] ^ 2, main = "Actual returns squared",
  cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)
grid()
```

```{r}
par(mfrow = c(1, 2))
acf(sv[, 1]^3)
acf(abs(sv[, 1]))
```

